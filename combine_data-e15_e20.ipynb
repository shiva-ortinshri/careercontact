{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'pandas'\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install 'pandas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 54)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import string\n",
    "\n",
    "responses = pd.DataFrame()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "for i in range(15,21):\n",
    "    event_df = pd.read_csv('responses/e{}_post.csv'.format(i))\n",
    "    event_df['event'] = 'e{}'.format(i)\n",
    "    responses = pd.concat([responses, event_df], ignore_index=True)\n",
    "\n",
    "responses_cleaned = pd.DataFrame()\n",
    "responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all irrelevant columns in responses. Only the final columns will be added to responses_cleaned for analysis. Currently, there are 54 columns at the start of cleaning. The next step will drop 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = responses.drop(columns=['#','Start Date (UTC)','Submit Date (UTC)','Network ID','Timestamp','Name','*Finally, reminder to please check out our Digital Skills Sprint application: bit.ly/ccdss2021 (happening this June to July 2021)*','Other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_cols = [colname for colname in responses.columns if colname.startswith('Select the option that best describes your knowledge')]\n",
    "interest_cols = [colname for colname in responses.columns if colname.startswith('Select the option that best describes your interest')]\n",
    "learn_cols = [colname for colname in responses.columns if colname.startswith('The webinar has taught me what I wanted to learn about')]\n",
    "other_profession_cols = [colname for colname in responses.columns if colname.startswith('Have you considered other professions outside of')]\n",
    "\n",
    "knowledge_dfs = [responses[colname] for colname in knowledge_cols]\n",
    "interest_dfs = [responses[colname] for colname in interest_cols]\n",
    "learn_dfs = [responses[colname] for colname in learn_cols]\n",
    "other_profession_dfs = [responses[colname] for colname in other_profession_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns to something more legible and combine similar questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_cleaned['event'] = responses['event'].astype(str)\n",
    "\n",
    "email_cols = [\"Firstly, what's your email address?\",'Username','Email']\n",
    "email_dfs = [responses[colname] for colname in email_cols]\n",
    "responses_cleaned['email'] = reduce(lambda x,y: x.combine_first(y), email_dfs).astype(str).str.lower()\n",
    "\n",
    "responses_cleaned['one_word'] = responses[\"One word to describe today's online experience\"].astype(str).str.lower().str.replace('[{}]'.format(string.punctuation), '').str.split().str[0]\n",
    "responses_cleaned['what_I_liked'] = responses[\"What I liked about today's session\"].astype(str)\n",
    "responses_cleaned['other_profession'] = reduce(lambda x,y: x.combine_first(y), other_profession_dfs).astype(str).str.lower()\n",
    "responses_cleaned['e15_ama_feedback'] = responses[\"What is something you wished Monica & Ashton could've touched on?\"].astype(str)\n",
    "responses_cleaned['future_topics'] = responses[\"CareerContact is thinking of hosting more AMA webinars in the future. What topics would interest you?\"].astype(str)\n",
    "\n",
    "reason_cols = [\"My school provides talks like these already, but I was just curious to hear what Monica & Ashton have to say\",\"My school doesn't provide talks like these at all\",\"I don't know who to ask about college applications overseas\",\"My teacher told me to sign up for this\",\"I heard that my friends were signing up, so I decided to sign up too\"]\n",
    "responses_cleaned['reason_curious'] = responses[\"My school provides talks like these already, but I was just curious to hear what Monica & Ashton have to say\"].notnull()\n",
    "responses_cleaned['reason_noschooltalks'] = responses[\"My school doesn't provide talks like these at all\"].notnull()\n",
    "responses_cleaned['reason_noguidance'] = responses[\"I don't know who to ask about college applications overseas\"].notnull()\n",
    "responses_cleaned['reason_teacher'] = responses[\"My teacher told me to sign up for this\"].notnull()\n",
    "responses_cleaned['reason_friend'] = responses[\"I heard that my friends were signing up, so I decided to sign up too\"].notnull()\n",
    "\n",
    "responses_cleaned['rating'] = responses[\"Rate your overall experience\"]\n",
    "responses_cleaned['continued_interest'] = responses[\"I would be keen to attend more of such webinars\"]\n",
    "responses_cleaned['enjoyed_session'] = responses[\"I enjoyed the session\"]\n",
    "responses_cleaned['learnt_session'] = responses[\"I learnt a lot from the session\"]\n",
    "responses_cleaned['motivatedby_session'] = responses[\"I am more motivated to join the same industry as the speakers after this sharing\"]\n",
    "responses_cleaned['mentor_interest'] = responses[\"I am interested in finding a mentor (for advice on future life).\"]\n",
    "responses_cleaned['mentor_find_difficulty'] = responses[\"How difficult is it to find a mentor?\"]\n",
    "responses_cleaned['major_info_difficulty'] = responses[\"How easy is it to find information about your desired major?\"]\n",
    "\n",
    "afi_cols = [\"What do you think *could have improved* in this AMA webinar?\",\"What are some things we could have done to make the session better?\",\"Area(s) for Improvement that I would like to suggest\"]\n",
    "afi_dfs = [responses[colname] for colname in afi_cols]\n",
    "responses_cleaned['improvements'] = reduce(lambda x,y: x.combine_first(y), afi_dfs).astype(str).str.lower()\n",
    "\n",
    "takeaway_cols = [\"What is your greatest takeaway from this session?\",\"What are some actionables that you would set for yourself after this webinar?/  How has your perspective changed?\"]\n",
    "takeaway_dfs = [responses[colname] for colname in takeaway_cols]\n",
    "responses_cleaned['takeaway'] = reduce(lambda x,y: x.combine_first(y), takeaway_dfs).astype(str).str.lower()\n",
    "\n",
    "responses_cleaned['most_helpful'] = responses['What did you find most helpful in the webinar?'].astype(str)\n",
    "responses_cleaned['speaker_feedback'] = responses[\"Anything that you would like to say to any of our speakers? :)\"].astype(str)\n",
    "responses_cleaned['other_comments'] = responses[\"Do you have any other feedback for the team? \"].astype(str).combine_first(responses[\"Any other feedback, comments or suggestions:\"]).astype(str)\n",
    "responses_cleaned['app_rating']=responses['The CareerContact app is user-friendly'].astype(str) \n",
    "responses_cleaned['other_profession'] = reduce(lambda x,y: x.combine_first(y), other_profession_dfs).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell creates the generalize() function which helps in mapping large lists of categories (like school data). Though this process is memory intensive, it will be useful and easy to maintain as the number of schools and the exceptions increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize(ser, match_name, default=None, regex=False, case=False):\n",
    "    \"\"\" Search a series for text matches.\n",
    "    Based on code from https://www.metasnake.com/blog/pydata-assign.html\n",
    "\n",
    "    ser: pandas series to search\n",
    "    match_name: tuple containing text to search for and text to use for normalization\n",
    "    default: If no match, use this to provide a default value, otherwise use the original text\n",
    "    regex: Boolean to indicate if match_name contains a  regular expression\n",
    "    case: Case sensitive search\n",
    "\n",
    "    Returns a pandas series with the matched value\n",
    "\n",
    "    \"\"\"\n",
    "    seen = None\n",
    "    for match, name in match_name:\n",
    "        mask = ser.str.contains(match, case=case, regex=regex, na=False)\n",
    "        if seen is None:\n",
    "            seen = mask\n",
    "        else:\n",
    "            seen |= mask\n",
    "        ser = ser.where(~mask, name)\n",
    "    if default:\n",
    "        ser = ser.where(seen, default)\n",
    "    else:\n",
    "        ser = ser.where(seen, ser.values)\n",
    "    return ser\n",
    "\n",
    "school_patterns = [('Hwa Chong', 'Hwa Chong Institution'), ('School of the Arts','School of the Arts'),\n",
    "                   ('Eunoia', 'Eunoia Junior College'),('Jurong Pioneer', 'Jurong Pioneer Junior College'),\n",
    "                   ('Saint Andrew', \"Saint Andrew's Junior College\"),('Jurong Pioneer', 'Jurong Pioneer Junior College'),\n",
    "                   ('CJC', \"Catholic Junior College\")]\n",
    "responses_cleaned['school'] = generalize(responses[\"What's your school?\"], school_patterns)\n",
    "school_col = responses_cleaned.pop('school')\n",
    "responses_cleaned.insert(2, 'school', school_col)\n",
    "\n",
    "grade_patterns = [('J1', '11'), ('J2','12'),('J3', '13'),('11', '11'), ('12','12'),('13', '13')]\n",
    "responses_cleaned['grade'] = generalize(responses[\"Which grade are you in?\"], grade_patterns)\n",
    "grade_col = responses_cleaned.pop('grade')\n",
    "responses_cleaned.insert(3, 'grade', grade_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_cleaned['knowledge'] = reduce(lambda x,y: x.combine_first(y), knowledge_dfs).astype(str) \n",
    "responses_cleaned['interest'] = reduce(lambda x,y: x.combine_first(y), interest_dfs).astype(str)  \n",
    "responses_cleaned['learn'] = reduce(lambda x,y: x.combine_first(y), learn_dfs).astype(str)  \n",
    "responses_cleaned['helpful'] = responses[\"Let's get going. How helpful was the advice that Monica and Ashton gave?\"].astype(str)\n",
    "\n",
    "def knowledge_categories(df_string):\n",
    "    if df_string.startswith('I know little or nothing about'):\n",
    "        return 1\n",
    "    elif 'certainty' in df_string:\n",
    "        return 2\n",
    "    elif df_string.startswith('I am able to articulate') and '& more' not in df_string and '& beyond' not in df_string:\n",
    "        return 3\n",
    "    elif df_string.startswith('I am able to articulate') and ('& more, e.g. challenges and trends' in df_string or '& beyond' in df_string):\n",
    "        return 4\n",
    "\n",
    "def interest_categories(df_string):\n",
    "    if df_string.startswith('I am now more likely'):\n",
    "        return 1\n",
    "    elif df_string.startswith('I am now less likely'):\n",
    "        return 2\n",
    "    elif df_string.startswith('I am neither more nor less'):\n",
    "        return 3\n",
    "    elif 'undecided' in df_string:\n",
    "        return 4\n",
    "\n",
    "def learn_categories(df_string):\n",
    "    if df_string == 'Agree':\n",
    "        return 1\n",
    "    elif df_string == 'Somewhat Agree' :\n",
    "        return 2\n",
    "    elif df_string == 'Somewhat Disagree':\n",
    "        return 3\n",
    "    elif df_string == 'Disagree':\n",
    "        return 4\n",
    "\n",
    "def helpful_categories(df_string):\n",
    "    if df_string.startswith('Really unhelpful'):\n",
    "        return 1\n",
    "    elif df_string.startswith('Not so helpful'):\n",
    "        return 2\n",
    "    elif df_string.startswith('It was alright'):\n",
    "        return 3\n",
    "    elif df_string.startswith('Helpful'):\n",
    "        return 4\n",
    "    elif df_string.startswith('Really helpful'):\n",
    "        return 5\n",
    "\n",
    "responses_cleaned['knowledge_coded'] = responses_cleaned.knowledge.apply(knowledge_categories)\n",
    "responses_cleaned['interest_coded'] = responses_cleaned.interest.apply(interest_categories)\n",
    "responses_cleaned['learn_coded'] = responses_cleaned.learn.apply(learn_categories)\n",
    "responses_cleaned['helpful_coded'] = responses_cleaned.helpful.apply(helpful_categories)\n",
    "\n",
    "responses_cleaned['learn_coded']= responses_cleaned['learn_coded'].combine_first(responses_cleaned['helpful_coded'])\n",
    "responses_cleaned['learn_coded']= responses_cleaned['learn_coded'].combine_first(responses_cleaned['learnt_session'])\n",
    "responses_cleaned=responses_cleaned.drop(columns=[\"interest\",\"learn\",\"knowledge\",\"helpful\",\"helpful_coded\",'learnt_session'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(responses_cleaned, 'data/postevent_responses_2.pandas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
